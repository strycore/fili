#!/usr/bin/python
import os
import sys
import hashlib
import sqlite3

DBPATH = os.path.join(os.path.expanduser('~'), '.fili.db')


class db_cursor():
    def __enter__(self):
        self.db_conn = sqlite3.connect(DBPATH)
        cursor = self.db_conn.cursor()
        return cursor

    def __exit__(self, type, value, traceback):
        self.db_conn.commit()
        self.db_conn.close()


def create_db():
    db_conn = sqlite3.connect(DBPATH)
    cursor = db_conn.cursor()
    cursor.execute("""CREATE TABLE files
                   (path text, size integer, hash text,
                    accessed integer, modified integer)""")
    db_conn.commit()
    db_conn.close()


def get_file_info(path):
    statinfo = os.stat(path)
    return {
        'path': path.decode('utf-8'),
        'size': statinfo.st_size,
        'accessed': statinfo.st_atime,
        'modified': statinfo.st_mtime,
    }


def index_file(cursor, path, filehash, fileinfo):
    print "Indexing %s" % fileinfo['path']
    cursor.execute("DELETE FROM files WHERE path=?", (fileinfo['path'], ))
    cursor.execute("INSERT INTO files VALUES (?, ?, ?, ?, ?)",
                   (fileinfo['path'], fileinfo['size'], filehash,
                    fileinfo['accessed'], fileinfo['modified']))


def index_path(path):
    with db_cursor() as cursor:
        for filepath in iter_dir(path):
            filehash = calculate_md5(filepath)
            fileinfo = get_file_info(filepath)
            index_file(cursor, filepath, filehash, fileinfo)


def iter_dupes():
    with db_cursor() as cursor:
        dupes = cursor.execute("""SELECT count(path), hash
                                  FROM files GROUP BY hash
                                  HAVING count(path) > 1 AND hash != '0'""")
        for dupehash in dupes.fetchall():
            filehash = dupehash[1]
            dupe_files = cursor.execute("""SELECT * FROM files WHERE hash=?""",
                                        (filehash, ))
            yield dupe_files.fetchall()


def delete_dupes():
    for dupe_group in iter_dupes():
        for index, dupefile in enumerate(dupe_group):
            filepath = dupefile[0].encode('utf-8')
            if index == 0:
                print "keeping " + filepath
            else:
                print "deleting " + filepath


def print_dupes():
    for dupe_group in iter_dupes():
        for dupefile in dupe_group:
            print dupefile[0].encode('utf-8')


def search_file(query):
    with db_cursor() as cursor:
        result = cursor.execute("SELECT * FROM files WHERE path LIKE '%s'" %
                                ('%' + query + '%'))
        for fileentry in result.fetchall():
            print fileentry[0].encode('utf-8')


def unindex(path):
    with db_cursor() as cursor:
        cursor.execute("DELETE FROM files WHERE path LIKE '%s'" % (path + '%'))


def calculate_md5(filename):
    md5 = hashlib.md5()
    try:
        with open(filename, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                md5.update(chunk)
    except IOError:
        print "Error reading %s" % filename
        return False
    return md5.hexdigest()


def iter_dir(path):
    for root, dirs, files in os.walk(path):
        for filename in files:
            yield os.path.join(root, filename)


if __name__ == "__main__":
    if not os.path.exists(DBPATH):
        create_db()
    if sys.argv[1] == "index":
        index_path(sys.argv[2])
    if sys.argv[1] == "dupes":
        print_dupes()
    if sys.argv[1] == "delete-dupes":
        delete_dupes()
    if sys.argv[1] == "unindex":
        unindex(sys.argv[2])
    if sys.argv[1] == "search":
        search_file(sys.argv[2])
